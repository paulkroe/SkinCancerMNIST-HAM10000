{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from skimage import io\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "import skimage.io as io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (600,450)\n",
    "creates dataloader, that holds a tensor representation of the whole (600,450) image. This is to big to work with.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split (80%)/(20%):\n",
    "\n",
    "source_folder = 'Data/HAM100000_images/'\n",
    "test_folder = 'Data/HAM100000_images_test/'\n",
    "train_folder = 'Data/HAM100000_images_train/'\n",
    "\n",
    "file_list = os.listdir(source_folder)\n",
    "\n",
    "number_test_images = math.ceil(0.2 * len(file_list))\n",
    "number_train_images = len(file_list) - number_test_images\n",
    "# TODO: Set manual seed and select number_test_images in and rest in 'Data/HAM100000_images_train' \n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "random_numbers = set()\n",
    "\n",
    "while len(random_numbers) <= number_test_images:\n",
    "    random_numbers.add(random.randint(0, len(file_list)-1))\n",
    "\n",
    "for index, file in enumerate(file_list):\n",
    "    if index in random_numbers:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(train_folder, file)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    else:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(test_folder, file)\n",
    "        shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id\n"
     ]
    }
   ],
   "source": [
    "# Create annotations file for given train/test split\n",
    "\n",
    "test_directory = 'Data/HAM100000_images_test/'\n",
    "\n",
    "with open('Data/HAM10000_labels.csv') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    print(next(csv_reader)[0])\n",
    "    write_test = []\n",
    "    write_train = []\n",
    "\n",
    "    for row in csv_reader:\n",
    "        path_image = os.path.join(test_directory, row[0])\n",
    "        path_image = path_image + '.jpg'\n",
    "        if os.path.isfile(path_image):\n",
    "            write_test.append([row[0], row[1]])\n",
    "        else:\n",
    "            write_train.append([row[0], row[1]])\n",
    "    \n",
    "with open('Data/HAM100000_train_label.csv', 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    for row in write_train:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "with open('Data/HAM100000_test_label.csv', 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    for row in write_test:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\HAM100000_images\\ISIC_0025030.jpg\n"
     ]
    }
   ],
   "source": [
    "# show an image\n",
    "root = 'Data\\HAM100000_images'\n",
    "frame = pd.read_csv('Data\\HAM10000_labels.csv')\n",
    "\n",
    "image_path = os.path.join(root, frame.iloc[0,0])\n",
    "image_path = image_path + '.jpg'\n",
    "with Image.open(image_path) as image:\n",
    "    image.show()\n",
    "\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194.69792020561766, 139.26262746509832, 145.48524135685338] [22.855094582223956, 30.168411555547745, 33.903190491317204]\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and std of dataset, all images have size (600, 450), after transforming images to tensors they have size (3, 600, 450)\n",
    "file_list = os.listdir('Data\\HAM100000_images')\n",
    "mean = [0, 0, 0]\n",
    "std = [0, 0, 0]\n",
    "\n",
    "for file_name in file_list:\n",
    "    image_path = os.path.join('Data\\HAM100000_images', file_name)\n",
    "    image = io.imread(image_path)\n",
    "    mean[0] += image[:, :, 0].mean()\n",
    "    mean[1] += image[:, :, 1].mean()\n",
    "    mean[2] += image[:, :, 2].mean()\n",
    "    std[0] += image[:, :, 0].std()\n",
    "    std[1] += image[:, :, 1].std()\n",
    "    std[2] += image[:, :, 2].std()    \n",
    "for i in [0, 1, 2]:\n",
    "    mean[i] /= len(file_list)\n",
    "    std[i] /= len(file_list)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[194.69792020561766, 139.26262746509832, 145.48524135685338], std=[22.855094582223956, 30.168411555547745, 33.903190491317204])\n",
    "])\n",
    "\n",
    "# to use these data needs to be in class folders\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='Data/HAM100000_images_train/', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='Data/HAM100000_images_test/', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 3, 450, 600])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "test = next(iter(train_loader))\n",
    "print(type(test))\n",
    "print(len(test))\n",
    "print(type(test[0]))\n",
    "print(test[0].shape)\n",
    "print(type(test[1]))\n",
    "print(test[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (28,28)\n",
    "With the dataset there comes a csv containing the same images compressed to (28,28), in a csv file. This is better to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train/test split\n",
    "random.seed(42)\n",
    "test_split  = set()\n",
    "while len(test_split) < 2000:\n",
    "    test_split.add(random.randint(0, 10015-1)) # HAM10000 has 10015 images\n",
    "\n",
    "#read csv file into list\n",
    "\n",
    "with open('Data/hmnist_28_28_RGB.csv') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)\n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CSV_Data(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shuffle = True\n",
    "\n",
    "train_input = []\n",
    "train_labels = []\n",
    "test_input = []\n",
    "test_labels = []\n",
    "\n",
    "for index, image in enumerate(data):\n",
    "    image = [float(pixel) for pixel in image]\n",
    "    if index in test_split:\n",
    "        test_input.append(torch.tensor([image[:-1][0:28*28], image[:-1][28*28:2*28*28], image[:-1][2*28*28:]])) # 3 channels\n",
    "        test_labels.append(torch.tensor(image[-1]))\n",
    "    else:\n",
    "        train_input.append(torch.tensor([image[:-1][0:28*28], image[:-1][28*28:2*28*28], image[:-1][2*28*28:]]))\n",
    "        train_labels.append(torch.tensor(image[-1]))\n",
    "train_loader = DataLoader(CSV_Data(train_input, train_labels), batch_size=batch_size, shuffle=shuffle)\n",
    "test_loader = DataLoader(CSV_Data(test_input, test_labels), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, dropout = False):\n",
    "        super(net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 75 * 100, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 7)\n",
    "\n",
    "        # less droupout in deeper layers\n",
    "        self.dropout = False \n",
    "        self.dropout_3 = nn.Dropout(p=0.3) \n",
    "        self.dropout_5 = nn.Dropout(p=0.5)\n",
    "    def forward(self, x, train=True):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 32 * 75 * 100)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        if train and self.dropout:\n",
    "            x = self.dropout_5(x)    \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        if train and self.dropout:\n",
    "            x = self.dropout_3(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "classes = ('akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "def train_model(model, data_loader, epochs, lr=0.1, optim=None):\n",
    "  if optim is None:\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
    "  else:\n",
    "    optimizer = optim\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  \n",
    "  model.to(device)\n",
    "  for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "      y_pred = model(X)\n",
    "      y_one_hot = torch.nn.functional.one_hot(y, num_classes=7)\n",
    "      loss = loss_fn(y_pred, y_one_hot)\n",
    "      epoch_loss += loss\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    print(f\"average batch loss in {epoch+1}: {epoch_loss/batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "def test_model(model, data_loader):\n",
    "  model.to(device)\n",
    "  with torch.no_grad():\n",
    "    right, wrong = np.array([0 for i in range(10)]), np.array([0 for i in range(10)])\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "      y_pred = model(X, train=False)\n",
    "      y_pred = torch.argmax(y_pred, dim=1)\n",
    "      for i in range(len(y_pred)):\n",
    "        if y_pred[i]==y[i]:\n",
    "          right[y[i]] += 1\n",
    "        else:\n",
    "         wrong[y[i]] += 1\n",
    "\n",
    "  for i in range(10):\n",
    "    print(f\"accuracy for {classes[i]}: {right[i]}/{right[i]+wrong[i]} | accuracy in %: {right[i]/(right[i]+wrong[i])*100}\")\n",
    "  \n",
    "  print(f\"overall accuracy: {np.sum(right)} / {np.sum(right) + np.sum(wrong)} | accuracy in percent % {100*np.sum(right)/(np.sum(right) + np.sum(wrong))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(iter(train_loader))\n",
    "model_0 = net()\n",
    "bing = model_0(test[0])\n",
    "# train_model(model_0, train_loader, epochs=3, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 450, 600])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bing.shape)\n",
    "test[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
