{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "create a pytorch Dataset from MVS10015 Dataset\n",
    "pytorch [documentaion](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from skimage import io\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split (80%)/(20%):\n",
    "\n",
    "source_folder = 'Data/HAM100000_images/'\n",
    "test_folder = 'Data/HAM100000_images_test/'\n",
    "train_folder = 'Data/HAM100000_images_train/'\n",
    "\n",
    "file_list = os.listdir(source_folder)\n",
    "\n",
    "number_test_images = math.ceil(0.2 * len(file_list))\n",
    "number_train_images = len(file_list) - number_test_images\n",
    "# TODO: Set manual seed and select number_test_images in and rest in 'Data/HAM100000_images_train' \n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "random_numbers = set()\n",
    "\n",
    "while len(random_numbers) <= number_test_images:\n",
    "    random_numbers.add(random.randint(0, len(file_list)-1))\n",
    "\n",
    "for index, file in enumerate(file_list):\n",
    "    if index in random_numbers:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(train_folder, file)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    else:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(test_folder, file)\n",
    "        shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id\n"
     ]
    }
   ],
   "source": [
    "# Create annotations file for given train/test split\n",
    "\n",
    "test_directory = 'Data/HAM100000_images_test/'\n",
    "\n",
    "with open('Data/HAM10000_labels.csv') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    print(next(csv_reader)[0])\n",
    "    write_test = []\n",
    "    write_train = []\n",
    "\n",
    "    for row in csv_reader:\n",
    "        path_image = os.path.join(test_directory, row[0])\n",
    "        path_image = path_image + '.jpg'\n",
    "        if os.path.isfile(path_image):\n",
    "            write_test.append([row[0], row[1]])\n",
    "        else:\n",
    "            write_train.append([row[0], row[1]])\n",
    "    \n",
    "with open('Data/HAM100000_train_label.csv', 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    for row in write_train:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "with open('Data/HAM100000_test_label.csv', 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    for row in write_test:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suibclass of Dataset class to load images and labels\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_annotation, root_dir, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.frame = pd.read_csv(csv_annotation)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_name = os.path.join(self.root_dir, self.frame.iloc[idx, 0])\n",
    "        image_name = image_name + '.jpg'\n",
    "        image = io.imread(image_name)\n",
    "\n",
    "        sample = {'image': image, 'label': self.frame.iloc[idx, 1]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\HAM100000_images\\ISIC_0025030.jpg\n"
     ]
    }
   ],
   "source": [
    "# show an image\n",
    "root = 'Data\\HAM100000_images'\n",
    "frame = pd.read_csv('Data\\HAM10000_labels.csv')\n",
    "\n",
    "image_path = os.path.join(root, frame.iloc[0,0])\n",
    "image_path = image_path + '.jpg'\n",
    "with Image.open(image_path) as image:\n",
    "    image.show()\n",
    "\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194.69792020561766, 139.26262746509832, 145.48524135685338] [22.855094582223956, 30.168411555547745, 33.903190491317204]\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and std of dataset, all images have size (600, 450), after transforming images to tensors they have size (3, 600, 450)\n",
    "file_list = os.listdir('Data\\HAM100000_images')\n",
    "mean = [0, 0, 0]\n",
    "std = [0, 0, 0]\n",
    "\n",
    "for file_name in file_list:\n",
    "    image_path = os.path.join('Data\\HAM100000_images', file_name)\n",
    "    image = io.imread(image_path)\n",
    "    mean[0] += image[:, :, 0].mean()\n",
    "    mean[1] += image[:, :, 1].mean()\n",
    "    mean[2] += image[:, :, 2].mean()\n",
    "    std[0] += image[:, :, 0].std()\n",
    "    std[1] += image[:, :, 1].std()\n",
    "    std[2] += image[:, :, 2].std()    \n",
    "for i in [0, 1, 2]:\n",
    "    mean[i] /= len(file_list)\n",
    "    std[i] /= len(file_list)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pytorch dataset and test ImageDatset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[194.69792020561766, 139.26262746509832, 145.48524135685338], std=[22.855094582223956, 30.168411555547745, 33.903190491317204])\n",
    "])\n",
    "\n",
    "training_data = ImageDataset(csv_annotation='Data/HAM100000_train_label.csv', root_dir='Data/HAM100000_images_train/', transform=transform)\n",
    "test_data = ImageDataset(csv_annotation='Data/HAM100000_test_label.csv', root_dir='Data/HAM100000_images_test/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[194.69792020561766, 139.26262746509832, 145.48524135685338], std=[22.855094582223956, 30.168411555547745, 33.903190491317204])\n",
    "])\n",
    "\n",
    "# to use these data needs to be in class folders\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='Data/HAM100000_images_train/', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='Data/HAM100000_images_test/', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
